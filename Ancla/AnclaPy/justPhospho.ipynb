{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from Ancla import Featurizer, RTDataset, BuModel, LandscapeExplorer, BottomUpResNet\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elabo\\AppData\\Local\\Temp\\ipykernel_21252\\966019312.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training_data = pd.read_csv(r\"D:\\DB_FullSequencesDistinct_noJurkat.csv\")\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv(r\"D:\\DB_FullSequencesDistinct_noJurkat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data[training_data['FullSequence'].str.contains('Phospho') | training_data['FullSequence'].str.contains('Carbamido') | training_data['FullSequence'].str.contains('Acetyl')]\n",
    "\n",
    "#base sequence less than 50 amino acids\n",
    "training_data = training_data[training_data['BaseSequence'].str.len() <= 50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.read_csv(r\"D:\\OtherPeptideResultsForTraining\\vocab.csv\")\n",
    "\n",
    "# make vocab a dictionary\n",
    "vocab = dict(zip(vocab[\"Id\"], vocab[\"Token\"]))\n",
    "#swap keys and values\n",
    "vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# change the word Phosphorylation to Phospho\n",
    "training_data = training_data.replace('Phosphorylation', 'Phospho', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                                                                             4\n",
      "AmbiguityLevel                                                                 1\n",
      "BaseSequence                         ALANVNIGSLICNVGAGGPAPAAGAAPAGGPAPSTAAAPAEEK\n",
      "FileName                           20100604_Velos1_TaGe_SA_A549_5-calib-averaged\n",
      "FullSequence                   ALANVNIGSLIC[Common Fixed:Carbamidomethyl on C...\n",
      "GeneName                                                           primary:RPLP1\n",
      "MassErrorDaltons                                                        -0.00028\n",
      "Notch                                                                          0\n",
      "OrganismName                                                        Homo sapiens\n",
      "PEP                                                                     0.000029\n",
      "PEPQvalue                                                               0.000018\n",
      "PeptideMonoisotopicMass                                               3807.92139\n",
      "PrecursorCharge                                                                3\n",
      "PrecursorMZ                                                           1270.31431\n",
      "PrecursorMass                                                         3807.92111\n",
      "PrecursorScanNumber                                                            0\n",
      "ProteinAccession                                                          P05386\n",
      "ProteinName                                      60S acidic ribosomal protein P1\n",
      "QValue                                                                       0.0\n",
      "ScanRetentionTime                                                     155.599725\n",
      "Score                                                                     40.298\n",
      "StartAndEndResidueInProtein                                           [50 to 92]\n",
      "TotalIonCurrent                                                     117206.06203\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "example = training_data.iloc[0]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vector(peptide, vocab):\n",
    "    peptide_dictionary = {\n",
    "        \"A\" : None, \n",
    "        \"C\" : None,\n",
    "        \"D\" : None,\n",
    "        \"E\" : None,\n",
    "        \"F\" : None,\n",
    "        \"G\" : None,\n",
    "        \"H\" : None,\n",
    "        \"I\" : None,\n",
    "        \"K\" : None,\n",
    "        \"L\" : None,\n",
    "        \"M\" : None,\n",
    "        \"N\" : None,\n",
    "        \"P\" : None,\n",
    "        \"Q\" : None,\n",
    "        \"R\" : None,\n",
    "        \"S\" : None,\n",
    "        \"T\" : None,\n",
    "        \"V\" : None,\n",
    "        \"W\" : None,\n",
    "        \"Y\" : None,\n",
    "        \"Precursor_Charge\" : None,\n",
    "        \"Precursor_MZ\" : None,\n",
    "        \"Precursor_Mass\" : None,\n",
    "        \"Precursor_Scan_Number\" : None,\n",
    "        \"Modifications\" : None,\n",
    "        \"Polar_Residues\" : None,\n",
    "        \"Hydrophobic_Residues\" : None,\n",
    "        \"Basic_Residues\" : None,\n",
    "        \"Acidic_Residues\" : None,\n",
    "        \"Aromatic_Residues\" : None,\n",
    "        \"Neutral_Residues\" : None,\n",
    "        \"Modification_Monoisotopic_Mass\" : None,\n",
    "    }\n",
    "\n",
    "    Modifications = {\n",
    "        \"Phospho\" : 79.966331,\n",
    "        \"Acetyl\" : 42.010565,\n",
    "        \"Carbamido\" : 43.005814,\n",
    "        \"Oxidation\" : 15.994915,\n",
    "        \"Deamidation\" : 0.984016,\n",
    "    }\n",
    "\n",
    "    Polar_Residues = [\"S\", \"T\", \"Y\", \"N\", \"Q\", \"C\"]\n",
    "    Hydrophobic_Residues = [\"A\", \"I\", \"L\", \"M\", \"F\", \"V\", \"W\"]\n",
    "    Basic_Residues = [\"K\", \"R\", \"H\"]\n",
    "    Acidic_Residues = [\"D\", \"E\"]\n",
    "    Aromatic_Residues = [\"F\", \"W\", \"Y\", \"H\"]\n",
    "    Neutral_Residues = [\"A\", \"G\", \"V\", \"L\", \"I\", \"P\", \"F\", \"W\", \"S\", \"T\", \"C\", \"Y\", \"M\", \"N\", \"Q\"]\n",
    "    Retention_Time = example[\"ScanRetentionTime\"]\n",
    "\n",
    "    # fill dictionary with values from example\n",
    "\n",
    "    # amino acid counts\n",
    "    for aa in peptide_dictionary.keys():\n",
    "        peptide_dictionary[aa] = example[\"BaseSequence\"].count(aa)\n",
    "\n",
    "    # precursor charge\n",
    "    peptide_dictionary[\"Precursor_Charge\"] = example[\"PrecursorCharge\"]\n",
    "\n",
    "    # precursor mz\n",
    "    peptide_dictionary[\"Precursor_MZ\"] = example[\"PrecursorMZ\"]\n",
    "\n",
    "    # precursor mass\n",
    "    peptide_dictionary[\"Precursor_Mass\"] = example[\"PrecursorMass\"]\n",
    "\n",
    "    # precursor scan number\n",
    "    peptide_dictionary[\"Precursor_Scan_Number\"] = example[\"PrecursorScanNumber\"]\n",
    "\n",
    "    # modifications\n",
    "    modifications = []\n",
    "    for mod in Modifications.keys():\n",
    "        if mod in example[\"FullSequence\"]:\n",
    "            modifications.append(mod)\n",
    "    peptide_dictionary[\"Modifications\"] = modifications\n",
    "\n",
    "    # polar residues\n",
    "    polar_residues = 0\n",
    "    for aa in Polar_Residues:\n",
    "        if aa in example[\"BaseSequence\"]:\n",
    "            polar_residues += 1\n",
    "    peptide_dictionary[\"Polar_Residues\"] = polar_residues\n",
    "\n",
    "    # hydrophobic residues\n",
    "    hydrophobic_residues = 0\n",
    "    for aa in Hydrophobic_Residues:\n",
    "        if aa in example[\"BaseSequence\"]:\n",
    "            hydrophobic_residues += 1\n",
    "    peptide_dictionary[\"Hydrophobic_Residues\"] = hydrophobic_residues\n",
    "\n",
    "    # basic residues\n",
    "    basic_residues = 0\n",
    "    for aa in Basic_Residues:\n",
    "        if aa in example[\"BaseSequence\"]:\n",
    "            basic_residues += 1\n",
    "    peptide_dictionary[\"Basic_Residues\"] = basic_residues\n",
    "\n",
    "    # acidic residues\n",
    "    acidic_residues = 0\n",
    "    for aa in Acidic_Residues:\n",
    "        if aa in example[\"BaseSequence\"]:\n",
    "            acidic_residues += 1\n",
    "    peptide_dictionary[\"Acidic_Residues\"] = acidic_residues\n",
    "\n",
    "    # aromatic residues\n",
    "    aromatic_residues = 0\n",
    "    for aa in Aromatic_Residues:\n",
    "        if aa in example[\"BaseSequence\"]:\n",
    "            aromatic_residues += 1\n",
    "    peptide_dictionary[\"Aromatic_Residues\"] = aromatic_residues\n",
    "\n",
    "    # neutral residues\n",
    "    neutral_residues = 0\n",
    "    for aa in Neutral_Residues:\n",
    "        if aa in example[\"BaseSequence\"]:\n",
    "            neutral_residues += 1\n",
    "    peptide_dictionary[\"Neutral_Residues\"] = neutral_residues\n",
    "\n",
    "    # modification monoisotopic mass\n",
    "    modification_monoisotopic_mass = 0\n",
    "    for mod in modifications:\n",
    "        modification_monoisotopic_mass += Modifications[mod]\n",
    "    peptide_dictionary[\"Modification_Monoisotopic_Mass\"] = modification_monoisotopic_mass\n",
    "\n",
    "    # print(peptide_dictionary)\n",
    "    peptide_vector = []\n",
    "    for key in peptide_dictionary.keys():\n",
    "        if key == \"Modifications\":\n",
    "            for mod in peptide_dictionary[key]:\n",
    "                peptide_vector.append(Modifications[mod])\n",
    "        else:\n",
    "            peptide_vector.append(peptide_dictionary[key])\n",
    "\n",
    "    # print(peptide_vector)\n",
    "    return torch.tensor(peptide_vector, dtype=torch.float32), Retention_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of feature vectors for each peptide in the training data\n",
    "feature_vectors = []\n",
    "retention_times = []\n",
    "for i in range(len(training_data)):\n",
    "    example = training_data.iloc[i]\n",
    "    feature_vectors.append(feature_vector(example, vocab))\n",
    "    retention_times.append(example[\"ScanRetentionTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors: 58833, Retention times: 58833\n",
      "Where feature vector length: 32\n",
      "Example feature vector: (tensor([1.4000e+01, 1.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 7.0000e+00,\n",
      "        0.0000e+00, 2.0000e+00, 1.0000e+00, 2.0000e+00, 0.0000e+00, 3.0000e+00,\n",
      "        6.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00, 1.0000e+00, 2.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 3.0000e+00, 1.2703e+03, 3.8079e+03, 0.0000e+00,\n",
      "        4.3006e+01, 4.0000e+00, 4.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "        1.0000e+01, 4.3006e+01]), 155.599725)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature vectors: {len(feature_vectors)}, Retention times: {len(retention_times)}\")\n",
    "print(f\"Where feature vector length: {len(feature_vectors[0][0])}\")\n",
    "print(f\"Example feature vector: {feature_vectors[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors: 29416, Retention times: 29416\n",
      "29416 29416\n",
      "[(tensor([7.0000e+00, 3.0000e+00, 1.0000e+00, 3.0000e+00, 1.0000e+00, 5.0000e+00,\n",
      "        1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "        3.0000e+00, 0.0000e+00, 1.0000e+00, 2.0000e+00, 3.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 3.0000e+00, 1.0738e+03, 3.2184e+03, 0.0000e+00,\n",
      "        4.3006e+01, 4.0000e+00, 3.0000e+00, 2.0000e+00, 2.0000e+00, 2.0000e+00,\n",
      "        9.0000e+00, 4.3006e+01]), 78.80394)]\n"
     ]
    }
   ],
   "source": [
    "#make a dataset class\n",
    "class PeptideDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.feature_vectors = data[:][0]\n",
    "        self.retention_times = data[:][1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature_vectors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.feature_vectors[idx], self.retention_times[idx]\n",
    "    \n",
    "\n",
    "print(f\"Feature vectors: {len(feature_vectors)}, Retention times: {len(retention_times)}\")\n",
    "\n",
    "#split the data into training and validation sets\n",
    "train_data, val_data = train_test_split((feature_vectors, retention_times), test_size=0.2)\n",
    "\n",
    "#make the data from a list of list into a list\n",
    "train_data = [list(x) for x in zip(*train_data)]\n",
    "val_data = [list(x) for x in zip(*val_data)]\n",
    "\n",
    "print(len(train_data), len(val_data))\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader size: 1\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     43\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 44\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     46\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "train_dataset = PeptideDataset(train_data)\n",
    "val_dataset = PeptideDataset(val_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "print(f\"Dataloader size: {len(train_dataset)}\")\n",
    "#make a model\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(32, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = RegressionModel()\n",
    "\n",
    "#train the model\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss/len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            val_loss += loss.item()\n",
    "        val_losses.append(val_loss/len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_losses[-1]}, Val Loss: {val_losses[-1]}\")\n",
    "\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#make a prediction\n",
    "example = training_data.iloc[0]\n",
    "feature_vector = feature_vector(example, vocab)[0]\n",
    "prediction = model(feature_vector)\n",
    "print(f\"Prediction: {prediction}, Actual: {example['ScanRetentionTime']}\")\n",
    "\n",
    "#save the model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "#load the model\n",
    "model = RegressionModel()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "#make a prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = Featurizer.featurize_all_full_sequences(training_data, vocab, 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Featurizer.pca_features(X)[:][0]\n",
    "y = Featurizer.normalize_targets(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 349.91it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 756.41it/s]\n",
      "Epoch :   1%|          | 1/100 [00:03<05:34,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.054001757793561145, Validation Loss : 0.048025247886015116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 361.33it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 718.87it/s]\n",
      "Epoch :   2%|▏         | 2/100 [00:06<05:26,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04743888768376664, Validation Loss : 0.04751614440160235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 353.78it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 843.99it/s]\n",
      "Epoch :   3%|▎         | 3/100 [00:10<05:23,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04706241448426523, Validation Loss : 0.04713817731651347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 360.81it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 763.89it/s]\n",
      "Epoch :   4%|▍         | 4/100 [00:13<05:18,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.046774770001358566, Validation Loss : 0.04682634556938068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 349.43it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 772.28it/s]\n",
      "Epoch :   5%|▌         | 5/100 [00:16<05:18,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.046506840569334344, Validation Loss : 0.04649849665292367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 365.53it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 746.96it/s]\n",
      "Epoch :   6%|▌         | 6/100 [00:19<05:11,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04621190100228496, Validation Loss : 0.04620628856751764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 347.79it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 639.14it/s]\n",
      "Epoch :   7%|▋         | 7/100 [00:23<05:12,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04591690778767852, Validation Loss : 0.045858722836154726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 363.86it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 763.26it/s]\n",
      "Epoch :   8%|▊         | 8/100 [00:26<05:06,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04561868394298629, Validation Loss : 0.04554669326534919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 366.97it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 794.98it/s]\n",
      "Epoch :   9%|▉         | 9/100 [00:29<05:00,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04532021428098757, Validation Loss : 0.045215848503806395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:02<00:00, 373.44it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 691.17it/s]\n",
      "Epoch :  10%|█         | 10/100 [00:33<04:53,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.045023965809487525, Validation Loss : 0.044928781881887626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:02<00:00, 375.18it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 777.52it/s]\n",
      "Epoch :  11%|█         | 11/100 [00:36<04:48,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.044746256741873665, Validation Loss : 0.04461197287019466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 365.19it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 685.45it/s]\n",
      "Epoch :  12%|█▏        | 12/100 [00:39<04:45,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.0444775170657687, Validation Loss : 0.04433156054216891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 367.11it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 592.81it/s]\n",
      "Epoch :  13%|█▎        | 13/100 [00:42<04:43,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.044219554818280694, Validation Loss : 0.044069468786302274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 369.91it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 690.97it/s]\n",
      "Epoch :  14%|█▍        | 14/100 [00:46<04:39,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04398830311773819, Validation Loss : 0.04381637289309549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 366.91it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 752.38it/s]\n",
      "Epoch :  15%|█▌        | 15/100 [00:49<04:35,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.043775641921486336, Validation Loss : 0.04362529236405795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 369.03it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 752.46it/s]\n",
      "Epoch :  16%|█▌        | 16/100 [00:52<04:32,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.043573427695450584, Validation Loss : 0.04347481931023953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 367.34it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 697.21it/s]\n",
      "Epoch :  17%|█▋        | 17/100 [00:55<04:29,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04338622657745749, Validation Loss : 0.043215023012817634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 370.69it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 763.48it/s]\n",
      "Epoch :  18%|█▊        | 18/100 [00:58<04:24,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04321216027844003, Validation Loss : 0.04301428293986358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 369.39it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 753.33it/s]\n",
      "Epoch :  19%|█▉        | 19/100 [01:02<04:21,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.043050454669574856, Validation Loss : 0.04283159180229277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 367.54it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 629.62it/s]\n",
      "Epoch :  20%|██        | 20/100 [01:05<04:18,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.042893751612224654, Validation Loss : 0.042668346511374196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 367.62it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 643.54it/s]\n",
      "Epoch :  21%|██        | 21/100 [01:08<04:16,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.042747977969301416, Validation Loss : 0.042551823749506876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 365.66it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 721.95it/s]\n",
      "Epoch :  22%|██▏       | 22/100 [01:11<04:13,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04263789467760652, Validation Loss : 0.042427878287707846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 361.46it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 766.16it/s]\n",
      "Epoch :  23%|██▎       | 23/100 [01:15<04:10,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04252968640618948, Validation Loss : 0.04233776038084379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 363.02it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 753.18it/s]\n",
      "Epoch :  24%|██▍       | 24/100 [01:18<04:07,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04242877994566257, Validation Loss : 0.04231421119654021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:02<00:00, 371.65it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 695.05it/s]\n",
      "Epoch :  25%|██▌       | 25/100 [01:21<04:03,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04234481011266424, Validation Loss : 0.04212614740277922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 364.99it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 759.74it/s]\n",
      "Epoch :  26%|██▌       | 26/100 [01:24<04:00,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04226599683328446, Validation Loss : 0.04205241570672093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 361.34it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 706.84it/s]\n",
      "Epoch :  27%|██▋       | 27/100 [01:28<03:58,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.042174172170800175, Validation Loss : 0.041967957024507056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 369.21it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 705.18it/s]\n",
      "Epoch :  28%|██▊       | 28/100 [01:31<03:54,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.0421185262232809, Validation Loss : 0.04191044261782614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 367.03it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 784.83it/s]\n",
      "Epoch :  29%|██▉       | 29/100 [01:34<03:50,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.0420451880701359, Validation Loss : 0.04183377764861113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 371.33it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 641.75it/s]\n",
      "Epoch :  30%|███       | 30/100 [01:37<03:46,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04197102928353778, Validation Loss : 0.04177611868299055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 369.91it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 828.71it/s]\n",
      "Epoch :  31%|███       | 31/100 [01:41<03:42,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04190922890376751, Validation Loss : 0.04169072847531225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 369.33it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 656.53it/s]\n",
      "Epoch :  32%|███▏      | 32/100 [01:44<03:39,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.041831019852070765, Validation Loss : 0.04164002562484634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 369.42it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 674.58it/s]\n",
      "Epoch :  33%|███▎      | 33/100 [01:47<03:36,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.041781445740816416, Validation Loss : 0.04166052755344034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 357.34it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 696.64it/s]\n",
      "Epoch :  34%|███▍      | 34/100 [01:50<03:35,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04173213108407906, Validation Loss : 0.04152967914687143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 369.38it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 758.00it/s]\n",
      "Epoch :  35%|███▌      | 35/100 [01:54<03:31,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04167302556621081, Validation Loss : 0.041498808144092264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 369.38it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 691.24it/s]\n",
      "Epoch :  36%|███▌      | 36/100 [01:57<03:27,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04162808309626678, Validation Loss : 0.041405271922646085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 366.80it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 585.37it/s]\n",
      "Epoch :  37%|███▋      | 37/100 [02:00<03:25,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.041572573201972815, Validation Loss : 0.04134162561665734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 367.21it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 694.66it/s]\n",
      "Epoch :  38%|███▊      | 38/100 [02:03<03:21,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04151867568770664, Validation Loss : 0.04141919760446367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 363.69it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 698.46it/s]\n",
      "Epoch :  39%|███▉      | 39/100 [02:07<03:18,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04146123642650555, Validation Loss : 0.041286233063386364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 367.42it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 675.31it/s]\n",
      "Epoch :  40%|████      | 40/100 [02:10<03:15,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04141709326968755, Validation Loss : 0.04124261498152536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 369.21it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 641.85it/s]\n",
      "Epoch :  41%|████      | 41/100 [02:13<03:11,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04135792796699952, Validation Loss : 0.041200062206413694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 361.29it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 738.77it/s]\n",
      "Epoch :  42%|████▏     | 42/100 [02:16<03:09,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04130724949119289, Validation Loss : 0.041142611227631624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 361.04it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 758.28it/s]\n",
      "Epoch :  43%|████▎     | 43/100 [02:20<03:06,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04126190225021242, Validation Loss : 0.04106046833906182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 355.27it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 750.63it/s]\n",
      "Epoch :  44%|████▍     | 44/100 [02:23<03:04,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04121032966983293, Validation Loss : 0.041033602320628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 357.58it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 585.24it/s]\n",
      "Epoch :  45%|████▌     | 45/100 [02:26<03:01,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04116516862277465, Validation Loss : 0.04096118008417624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 361.19it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 762.44it/s]\n",
      "Epoch :  46%|████▌     | 46/100 [02:30<02:58,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04112499748296123, Validation Loss : 0.04098421817153583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 356.83it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 639.15it/s]\n",
      "Epoch :  47%|████▋     | 47/100 [02:33<02:56,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04108537025051645, Validation Loss : 0.04093497230563764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1114/1114 [00:03<00:00, 361.45it/s]\n",
      "Validating: 100%|██████████| 139/139 [00:00<00:00, 850.34it/s]\n",
      "Epoch :  48%|████▊     | 48/100 [02:36<02:51,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.04103182998327113, Validation Loss : 0.040835822575014086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 112/1114 [00:00<00:03, 307.33it/s]\n",
      "Epoch :  48%|████▊     | 48/100 [02:37<02:50,  3.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[271], line 36\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Explore the landscape \u001b[39;00m\n\u001b[0;32m     30\u001b[0m explorer \u001b[38;5;241m=\u001b[39m LandscapeExplorer(model \u001b[38;5;241m=\u001b[39m model, criterion \u001b[38;5;241m=\u001b[39m criterion, optimizer \u001b[38;5;241m=\u001b[39m optimizer,\n\u001b[0;32m     31\u001b[0m                                 training_dataloader \u001b[38;5;241m=\u001b[39m train_loader,\n\u001b[0;32m     32\u001b[0m                                 validation_dataloader \u001b[38;5;241m=\u001b[39m validation_loader,\n\u001b[0;32m     33\u001b[0m                                 testing_dataset \u001b[38;5;241m=\u001b[39m test_dataset,\n\u001b[0;32m     34\u001b[0m                                 num_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, range_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m \u001b[43mexplorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m explorer\u001b[38;5;241m.\u001b[39mtest()\n",
      "File \u001b[1;32mc:\\Users\\elabo\\Documents\\GitHub\\Ancla\\Ancla\\AnclaPy\\Ancla.py:880\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m    878\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 880\u001b[0m     epochs_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_dataloader, total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_dataloader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    882\u001b[0m         inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), targets\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\elabo\\Documents\\GitHub\\Ancla\\Ancla\\AnclaPy\\Ancla.py:766\u001b[0m, in \u001b[0;36m__train_step__\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    765\u001b[0m \u001b[38;5;66;03m# Function to train the model for a few steps\u001b[39;00m\n\u001b[1;32m--> 766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__train_step__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: torch\u001b[38;5;241m.\u001b[39mTensor, y: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\elabo\\anaconda3\\envs\\PyInstallerForPlots\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elabo\\anaconda3\\envs\\PyInstallerForPlots\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elabo\\anaconda3\\envs\\PyInstallerForPlots\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\elabo\\anaconda3\\envs\\PyInstallerForPlots\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elabo\\anaconda3\\envs\\PyInstallerForPlots\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elabo\\anaconda3\\envs\\PyInstallerForPlots\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sequential model to be used to predict retention time\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(55, 25),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(25, 1)\n",
    ")\n",
    "model.double()\n",
    "\n",
    "# Divide training features into train and test\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_validate, y_validate, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "# Create data sets\n",
    "train_dataset = RTDataset(X_train, y_train)\n",
    "validation_dataset = RTDataset(X_validate, y_validate)\n",
    "test_dataset = RTDataset(X_test, y_test)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "\n",
    "# Explore the landscape \n",
    "explorer = LandscapeExplorer(model = model, criterion = criterion, optimizer = optimizer,\n",
    "                                training_dataloader = train_loader,\n",
    "                                validation_dataloader = validation_loader,\n",
    "                                testing_dataset = test_dataset,\n",
    "                                num_points = 10, range_ = 1)\n",
    "\n",
    "explorer.train(epochs = 500)\n",
    "explorer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Ancla.RTDataset at 0x22683897560>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyInstallerForPlots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
